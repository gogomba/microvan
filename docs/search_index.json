[["index.html", "Microvan About", " Microvan Hammond 2022-05-30 About The case describes a project by Grosse Pointe Associates (GPA) investigating the potential market for “microvans”. The objectives of this case are: 1. To give you experience segmenting customers in a market 2. To have you determine which segment(s) would be good to target based on analysis of the data. 3. To have you relate the segment(s) to demographic variables potentially useful for targeting # multivariate analysis and basic descriptive statistics library(psych) # data processing library(dplyr) library(tidyverse) library(data.table) library(DT) # plot library(ggplot2) library(corrplot) library(ggthemes) # rMarkdown library(rmarkdown) library(kableExtra) # file path management library(here) # stat library(factoextra) "],["executive-summary.html", "Chapter1 Executive Summary", " Chapter1 Executive Summary The case describes a project by Grosse Pointe Associates (GPA) investigating the potential market for “microvans”. The objectives of this case are: 1. To give you experience segmenting customers in a market 2. To have you determine which segment(s) would be good to target based on analysis of the data. 3. To have you relate the segment(s) to demographic variables potentially useful for targeting. "],["explorative-data-analysis.html", "Chapter2 Explorative Data Analysis 2.1 Histogram 2.2 Correlation Analysis", " Chapter2 Explorative Data Analysis # data dataPath = file.path(dataDir, &quot;microvan.csv&quot;) microvan = read.csv(dataPath, sep=&quot;;&quot;) # Convert all integer variables into numeric ones for futher work microvan &lt;- as.data.table(lapply(microvan, as.numeric)) # data description description = psych::describe(microvan) %&gt;% as.data.frame() # columns that need to be formatted numCols = c(&quot;mean&quot;, &quot;sd&quot;, &quot;median&quot; , &quot;trimmed&quot;, &quot;mad&quot;, &quot;min&quot;, &quot;max&quot;, &quot;skew&quot;, &quot;kurtosis&quot;, &quot;se&quot;) DT::datatable(description, options = list(pageLength = 10, scrollX = TRUE, scrollY = TRUE) )%&gt;% DT::formatRound(columns=numCols , digits=1) 2.1 Histogram 2.2 Correlation Analysis 2.2.1 Pair-wise Scatter Plot 2.2.2 Correlation Matrix "],["exploratory-factor-analysis.html", "Chapter3 Exploratory Factor Analysis 3.1 Eigenvalues 3.2 Extract Principal Factors 3.3 Factor Loadings 3.4 Factor Scores", " Chapter3 Exploratory Factor Analysis 3.1 Eigenvalues # correlation analysis without mvliking cor&lt;- cor(vars[,-1]) EV = eigen(cor)$values EV_df = EV %&gt;% # convert to df as.data.frame()%&gt;% # name column dplyr::rename(., &quot;Eigen Value&quot; =&quot;.&quot;) %&gt;% # add a column &quot;Factor&quot; dplyr::mutate(Factor = seq(1,length(EV))) %&gt;% # order columns dplyr::select(Factor, everything()) %&gt;% # add a column &quot;Variance&quot; dplyr::mutate(`Variance %` = EV/length(EV) *100) %&gt;% dplyr::mutate(`Cumulative Variance % ` = cumsum(EV/length(EV))* 100) %&gt;% dplyr::mutate(., across(where(is.numeric), round, 1)) rmarkdown::paged_table(EV_df ) 3.1.1 Scree Plot psych::scree(cor, pc = TRUE, factors = FALSE) 3.1.2 Cumulative Percentages of Variance # Shares for the cumulative variance explained plot(cumsum(EV/length(EV)), type = &quot;o&quot;, # type of plot: &quot;o&quot; for points and lines &#39;overplotted&#39; col = &quot;darkblue&quot;, pch = 16, # plot symbol: 16 = filled circle cex = 1, # size of plot symbols xlab = &quot;Number of factors&quot;, # a title for the x axis ylab = &quot;Cumulative variance explained&quot;, # a title for the y axis lwd = 2) # line width abline(v = 5, lwd = 2, col = &quot;grey&quot;) # draw a vertical line at v = 3 3.1.3 Select Number of Factors using Kaiser Rule nFactor &lt;- length(which(EV &gt; 1)) print(paste0(nFactor, &quot; factors with Eigenvalue &gt; 1&quot; )) ## [1] &quot;5 factors with Eigenvalue &gt; 1&quot; 3.2 Extract Principal Factors EFA &lt;- psych::fa( r = cor, # number of factors nfactors = nFactor, # principal factor fm = &quot;pa&quot;, # maximizes the sum of the variance of the squared loadings rotate = &quot;varimax&quot; ) 3.3 Factor Loadings columnOrder &lt;- c(&quot;PA1&quot;, &quot;PA2&quot;, &quot;PA3&quot;, &quot;PA4&quot;,&quot;PA5&quot;,&quot;Communality&quot;,&quot;Uniqueness&quot;) EFA_loadings &lt;- data.frame(EFA$loadings[,] ) %&gt;% dplyr::mutate(Uniqueness = EFA$uniquenesses, Communality = EFA$communality) %&gt;% dplyr::mutate(., across(where(is.numeric), round, 2)) %&gt;% dplyr::select(columnOrder) %&gt;% arrange(., -Communality) DT::datatable(EFA_loadings) 3.4 Factor Scores # extract rotated factor scores EFA.scores = factor.scores(vars[,-1], unclass(EFA$loadings))$scores DT_cols = c(&quot;PA1&quot;,&quot;PA2&quot;,&quot;PA3&quot;,&quot;PA4&quot;,&quot;PA5&quot;) EFA.scores %&gt;% as.data.frame()%&gt;% mutate(subjnumb = microvan_df$subjnumb)%&gt;% head(5) %&gt;% DT::datatable(caption = &quot;Top 5 rows&quot;) %&gt;% DT::formatRound(columns=DT_cols , digits=2) "],["regression-with-5-factors.html", "Chapter4 Regression with 5 Factors", " Chapter4 Regression with 5 Factors # data for regression EFA_with_score &lt;- cbind.data.frame(vars[,2], EFA.scores) %&gt;% dplyr::rename(., mvliking = &quot;vars[, 2]&quot; ) EFA_model &lt;- lm(mvliking ~ PA1 + PA2 +PA3+PA4 +PA5, data=EFA_with_score ) summary(EFA_model) ## ## Call: ## lm(formula = mvliking ~ PA1 + PA2 + PA3 + PA4 + PA5, data = EFA_with_score) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.7272 -0.0848 -0.0030 0.0900 0.9830 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.05e-16 7.80e-03 0.00 1.0000 ## PA1 1.22e-01 7.81e-03 15.64 &lt;2e-16 *** ## PA2 2.29e-03 7.81e-03 0.29 0.7694 ## PA3 9.80e-01 7.81e-03 125.54 &lt;2e-16 *** ## PA4 3.03e-03 7.81e-03 0.39 0.6983 ## PA5 -2.42e-02 7.81e-03 -3.10 0.0021 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.16 on 394 degrees of freedom ## Multiple R-squared: 0.976, Adjusted R-squared: 0.976 ## F-statistic: 3.2e+03 on 5 and 394 DF, p-value: &lt;2e-16 # merge with all previous data #EFA_merge_data &lt;- cbind(microvan, EFA.scores) #head(EFA_merge_data) "],["regression-with-3-factors.html", "Chapter5 Regression with 3 Factors", " Chapter5 Regression with 3 Factors # data for regression EFA_model2 &lt;- lm(mvliking ~ PA1 + PA3 + PA5, data=EFA_with_score ) summary(EFA_model2) ## ## Call: ## lm(formula = mvliking ~ PA1 + PA3 + PA5, data = EFA_with_score) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.7268 -0.0841 -0.0035 0.0910 0.9816 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.06e-16 7.78e-03 0.00 1.000 ## PA1 1.22e-01 7.79e-03 15.68 &lt;2e-16 *** ## PA3 9.80e-01 7.79e-03 125.82 &lt;2e-16 *** ## PA5 -2.42e-02 7.79e-03 -3.11 0.002 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.16 on 396 degrees of freedom ## Multiple R-squared: 0.976, Adjusted R-squared: 0.976 ## F-statistic: 5.36e+03 on 3 and 396 DF, p-value: &lt;2e-16 # merge with all previous data #EFA_merge_data &lt;- cbind(microvan, EFA.scores) #head(EFA_merge_data) "],["clustering.html", "Chapter6 Clustering 6.1 Interpretation of the results", " Chapter6 Clustering EFA_feature = EFA_with_score %&gt;% dplyr::select(PA1, PA2,PA4) # Run a cluster analysis on a distance matrix and using the Ward method c&lt;- hclust(dist(EFA_feature), method=&quot;ward.D2&quot;) # Dendrogram library(dendextend) plot(set(as.dendrogram(c), &quot;branches_k_color&quot;, # to highlight the cluster solution with a color k = 3), ylab = &quot;Distance&quot;, main = &quot;Dendrogram&quot;, cex = 0.2) set.seed(42) EFA_kmeans &lt;- kmeans(EFA_feature , centers = 3) EFA_kmeans ## K-means clustering with 3 clusters of sizes 118, 157, 125 ## ## Cluster means: ## PA1 PA2 PA4 ## 1 0.70 -1.133 0.013 ## 2 -1.01 -0.038 -0.064 ## 3 0.61 1.117 0.069 ## ## Clustering vector: ## [1] 2 3 1 3 1 1 3 2 1 2 2 1 2 1 3 3 3 3 2 2 2 2 3 2 2 1 2 3 2 1 ## [31] 2 1 2 1 1 1 1 3 1 1 3 2 2 2 2 3 2 1 1 2 1 1 2 1 2 2 3 1 3 2 ## [61] 1 2 2 2 3 2 2 3 3 1 3 2 2 1 1 2 2 1 2 3 1 2 2 2 1 2 2 1 2 2 ## [91] 1 3 2 3 1 1 1 2 2 2 2 1 2 2 2 3 2 3 1 1 3 3 2 3 2 3 3 2 2 2 ## [121] 1 2 3 1 3 2 2 2 3 2 1 1 1 3 3 1 1 1 3 3 3 1 2 2 3 2 3 3 2 2 ## [151] 1 2 3 3 1 2 3 2 1 3 3 1 3 2 2 2 1 1 2 1 3 2 2 3 1 3 1 3 3 1 ## [181] 2 2 3 1 3 2 1 2 2 1 3 1 2 2 3 2 2 3 3 2 3 2 1 2 1 1 2 1 2 3 ## [211] 1 3 2 1 1 2 1 3 2 1 3 2 1 2 1 2 3 2 3 2 2 1 1 1 1 1 1 3 2 3 ## [241] 2 3 3 2 1 2 3 1 2 2 1 2 3 3 3 2 1 2 2 3 1 1 1 3 1 3 2 2 3 2 ## [271] 1 2 1 2 3 1 3 2 2 3 1 3 3 3 1 2 2 1 3 3 3 2 2 3 3 2 1 3 3 1 ## [301] 3 2 1 3 2 1 3 3 1 2 2 2 2 3 2 3 2 3 3 1 2 3 2 3 2 3 2 2 2 3 ## [331] 3 2 1 3 3 2 2 2 3 2 1 1 1 1 1 3 2 3 1 2 3 2 1 2 1 3 3 3 1 3 ## [361] 3 3 2 3 2 2 2 3 3 2 1 1 3 3 3 1 3 2 1 1 3 1 1 3 2 2 1 2 1 2 ## [391] 1 2 3 1 1 2 2 3 3 2 ## ## Within cluster sum of squares by cluster: ## [1] 162 255 207 ## (between_SS / total_SS = 47.9 %) ## ## Available components: ## ## [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; ## [5] &quot;tot.withinss&quot; &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; ## [9] &quot;ifault&quot; # factor plot fviz_cluster(EFA_kmeans, data = EFA_feature) + theme_bw() 6.1 Interpretation of the results 6.1.1 Histogram # Average for each cluster with one step vars_cluster_agg = aggregate(vars_cluster[, 2:31], by = list(cluster = EFA_kmeans$cluster), FUN = mean) # reshape df &lt;- vars_cluster_agg %&gt;% gather(variable, value, -cluster) # to transfrom from wide to long format 6.1.2 Heatmap Table library(gt) library(scales) # reshpae, long to wide (cluster ) df_wider = df%&gt;% dplyr::mutate(cluster = paste0(&quot;Cluster&quot;, cluster)) %&gt;% dplyr::mutate(., across(where(is.numeric), round, 2)) %&gt;% spread(., key=cluster, value =value) # cluster columns clusterCols = c(&quot;Cluster1&quot;, &quot;Cluster2&quot;, &quot;Cluster3&quot;) # color colfunc &lt;- colorRampPalette(c(&quot;darkblue&quot;, &quot;lightgrey&quot;)) # DT table DT::datatable(bytopic, options = list(pageLength = 15)) %&gt;% formatStyle(&quot;Cluster1&quot;, backgroundColor = styleEqual(sort(unique(bytopic$Cluster1), decreasing = TRUE), colfunc(length( unique(bytopic$Cluster1) )))) %&gt;% formatStyle(&quot;Cluster2&quot;, backgroundColor = styleEqual(sort(unique(bytopic$Cluster2), decreasing = TRUE), colfunc(length( unique(bytopic$Cluster2) )))) %&gt;% formatStyle(&quot;Cluster3&quot;, backgroundColor = styleEqual(sort(unique(bytopic$Cluster3), decreasing = TRUE), colfunc(length( unique(bytopic$Cluster3) )))) %&gt;% formatStyle(clusterCols, color = &quot;white&quot;) "],["demographic.html", "Chapter7 Demographic", " Chapter7 Demographic "],["references.html", "References", " References Reducing Dimensionality Latent Dimensions of Customer Perceptions Hierarchical Clustering Preference Segmentation Preference Segmentation - Validation "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
